{
 "metadata": {
  "name": "",
  "signature": "sha256:93d3e418ea85a729b2c656cdca640e9c728f7d0768678e5053c815232961e57b"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cv2\n",
      "import numpy as np\n",
      "\n",
      "import PythonModel3dTracker.PyMBVAll as mbv\n",
      "import PythonModel3dTracker.Paths as Paths\n",
      "import PythonModel3dTracker.PythonModelTracker.DatasetInfo as dsi\n",
      "import PythonModel3dTracker.PythonModelTracker.OpenPoseGrabber as OPG\n",
      "import PythonModel3dTracker.PythonModelTracker.AutoGrabber as AutoGrabber\n",
      "import PythonModel3dTracker.Paths as Paths\n",
      "import BlenderMBV.BlenderMBVLib.RenderingUtils as ru\n",
      "import PythonModel3dTracker.PythonModelTracker.Model3dUtils as m3dutils\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/mad/Development/catkin_ws/src/ms1_perception/src/PythonModel3dTracker/PyMBVAll.py:1: RuntimeWarning: to-Python converter for std::vector<float, std::allocator<float> > already registered; second conversion method ignored.\n",
        "  import PyMBVCore as Core\n",
        "/home/mad/Development/catkin_ws/src/ms1_perception/src/PythonModel3dTracker/PyMBVAll.py:6: RuntimeWarning: to-Python converter for boost::function<void (cv::Mat_<double>&)> already registered; second conversion method ignored.\n",
        "  import PyMBVParticleFilter as PF\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/mad/Development/catkin_ws/src/ms1_perception/src/PythonModel3dTracker/PythonModelTracker/OpenPoseGrabber.py:2: RuntimeWarning: to-Python converter for cv::Mat already registered; second conversion method ignored.\n",
        "  import PyOpenPose as OP\n",
        "/home/mad/Development/catkin_ws/src/ms1_perception/src/PythonModel3dTracker/PythonModelTracker/OpenPoseGrabber.py:2: RuntimeWarning: to-Python converter for cv::Size_<int> already registered; second conversion method ignored.\n",
        "  import PyOpenPose as OP\n",
        "/home/mad/Development/catkin_ws/src/ms1_perception/src/PythonModel3dTracker/PythonModelTracker/OpenPoseGrabber.py:2: RuntimeWarning: to-Python converter for std::vector<cv::Mat, std::allocator<cv::Mat> > already registered; second conversion method ignored.\n",
        "  import PyOpenPose as OP\n",
        "/home/mad/Development/catkin_ws/src/ms1_perception/src/PythonModel3dTracker/PythonModelTracker/LandmarksGrabber.py:5: RuntimeWarning: to-Python converter for boost::shared_ptr<MBV::HandTracking::ObjectiveResultsCombination> already registered; second conversion method ignored.\n",
        "  import PyModel3dTracker as mt\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/mad/Development/catkin_ws/src/ms1_perception/src/PythonModel3dTracker/PythonModelTracker/LandmarksGrabber.py:5: RuntimeWarning: to-Python converter for std::__cxx11::list<unsigned long, std::allocator<unsigned long> > already registered; second conversion method ignored.\n",
        "  import PyModel3dTracker as mt\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dataset = 'mhad_s01_a04'\n",
      "params_ds = dsi.DatasetInfo()\n",
      "params_ds.generate(dataset)\n",
      "grabber = AutoGrabber.create_di(params_ds)\n",
      "opg = OPG.OpenPoseGrabber(model_op_path=Paths.models_openpose)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "images, calibs = grabber.grab()\n",
      "point_names, keypoints, keypoints2d, clb = opg.acquire(images, calibs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "person 0 Nose [ 211.9203949   122.07077026    0.85284293]\n",
        "person 0 neck [ 229.94139099  171.96713257    0.90738583]\n",
        "person 0 R.UArm [ 202.04627991  170.08081055    0.87641191]\n",
        "person 0 R.LArm [ 197.9125061   218.02832031    0.86750406]\n",
        "person 0 R.Wrist [ 185.99832153  261.90991211    0.85892105]\n",
        "person 0 L.UArm [ 250.01768494  172.02742004    0.84517473]\n",
        "person 0 L.LArm [ 262.00033569  228.01994324    0.87854463]\n",
        "person 0 L.Wrist [ 258.03451538  268.04766846    0.82357317]\n",
        "person 0 R.ULeg [ 208.01152039  265.99334717    0.78092176]\n",
        "person 0 R.LLeg [ 213.90013123  331.97756958    0.8679629 ]\n",
        "person 0 R.Foot [ 211.993927    385.95462036    0.86154634]\n",
        "person 0 L.ULeg [ 242.00204468  265.99411011    0.78002167]\n",
        "person 0 L.LLeg [ 250.0602417   337.97387695    0.81015623]\n",
        "person 0 L.Foot [ 261.9861145   396.03390503    0.86260402]\n",
        "person 0 R.eye [ 204.03909302  119.92331696    0.81368858]\n",
        "person 0 L.eye [ 216.02323914  118.08976746    0.95728999]\n",
        "person 0 R.ear [ 0.  0.  0.]\n",
        "person 0 L.ear [ 234.04742432  125.99485779    0.87714827]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/mad/Development/catkin_ws/src/ms1_perception/src/PythonModel3dTracker/PythonModelTracker/OpenPoseGrabber.py:154: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
        "  max(x-w, 0):min(x+w, width-1)])\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_name = \"mh_body_male_custom\"\n",
      "model3d = mbv.PF.Model3dMeta.create(str(Paths.model3d_dict[model_name][\"path\"]))\n",
      "model3d.parts.genBonesMap()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "\n",
      "interpolate_set = [\"R.UArm\", \"R.LArm\",\"R.ULeg\", \"R.LLeg\",\"L.UArm\", \"L.LArm\",\"L.ULeg\", \"L.LLeg\"]\n",
      "children = m3dutils.GetNodeChildren(model3d)\n",
      "\n",
      "kp2d_dict = {}\n",
      "for n,p2d in zip(point_names, keypoints2d[0]): kp2d_dict[n] = p2d\n",
      "kp3d_dict = {}\n",
      "for n,p3d in zip(point_names, keypoints[0]): kp3d_dict[n] = p3d\n",
      "    \n",
      "def p2d_interp(p0, p1, n):\n",
      "    X = np.linspace(p0.x, p1.x, n)\n",
      "    Y = np.linspace(p0.y, p1.y, n)\n",
      "    points = mbv.Core.Vector2fStorage()\n",
      "    for x,y in zip(X,Y): points.append(mbv.Core.Vector2(x,y))\n",
      "    return points\n",
      "\n",
      "def p3d_interp(p0, p1, n):\n",
      "    X = np.linspace(p0.x, p1.x, n)\n",
      "    Y = np.linspace(p0.y, p1.y, n)\n",
      "    Z = np.linspace(p0.z, p1.z, n)\n",
      "    points = mbv.Core.Vector3fStorage()\n",
      "    for x,y,z in zip(X,Y,Z): points.append(mbv.Core.Vector3(x,y,z))\n",
      "    return points\n",
      "    \n",
      "        \n",
      "m = 5\n",
      "points = mbv.Core.Vector2fStorage()\n",
      "for n in interpolate_set:\n",
      "    p0 = kp2d_dict[n]\n",
      "    p1 = kp2d_dict[children[n][0]]\n",
      "    cur_points = p2d_interp(p0,p1,m)\n",
      "    print n,p0,p1\n",
      "    #print cur_points\n",
      "    for p in cur_points: points.append(p)\n",
      "print points\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "R.UArm [202.04627990722656, 170.080810546875] [197.91250610351562, 218.0283203125]\n",
        "R.LArm [197.91250610351562, 218.0283203125] [185.99832153320312, 261.909912109375]\n",
        "R.ULeg [208.0115203857422, 265.99334716796875] [213.90013122558594, 331.9775695800781]\n",
        "R.LLeg [213.90013122558594, 331.9775695800781] [211.99392700195312, 385.9546203613281]\n",
        "L.UArm [250.01768493652344, 172.0274200439453] [262.0003356933594, 228.0199432373047]\n",
        "L.LArm [262.0003356933594, 228.0199432373047] [258.0345153808594, 268.04766845703125]\n",
        "L.ULeg [242.00204467773438, 265.9941101074219] [250.06024169921875, 337.973876953125]\n",
        "L.LLeg [250.06024169921875, 337.973876953125] [261.9861145019531, 396.0339050292969]\n",
        "[[202.04627990722656, 170.080810546875], [201.01283264160156, 182.06768798828125], [199.97940063476562, 194.0545654296875], [198.94595336914062, 206.04144287109375], [197.91250610351562, 218.0283203125], [197.91250610351562, 218.0283203125], [194.9339599609375, 228.99871826171875], [191.95541381835938, 239.9691162109375], [188.97686767578125, 250.93951416015625], [185.99832153320312, 261.909912109375], [208.0115203857422, 265.99334716796875], [209.48367309570312, 282.4894104003906], [210.95582580566406, 298.9854736328125], [212.427978515625, 315.48150634765625], [213.90013122558594, 331.9775695800781], [213.90013122558594, 331.9775695800781], [213.423583984375, 345.4718322753906], [212.947021484375, 358.9660949707031], [212.47047424316406, 372.4603576660156], [211.99392700195312, 385.9546203613281], [250.01768493652344, 172.0274200439453], [253.0133514404297, 186.02554321289062], [256.0090026855469, 200.023681640625], [259.0046691894531, 214.02182006835938], [262.0003356933594, 228.0199432373047], [262.0003356933594, 228.0199432373047], [261.0088806152344, 238.02687072753906], [260.0174255371094, 248.0338134765625], [259.0259704589844, 258.0407409667969], [258.0345153808594, 268.04766845703125], [242.00204467773438, 265.9941101074219], [244.0166015625, 283.9890441894531], [246.03114318847656, 301.9840087890625], [248.04568481445312, 319.97894287109375], [250.06024169921875, 337.973876953125], [250.06024169921875, 337.973876953125], [253.04171752929688, 352.4888916015625], [256.023193359375, 367.00390625], [259.004638671875, 381.5188903808594], [261.9861145019531, 396.0339050292969]]\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "viz = images[1]\n",
      "viz = ru.disp_points(points, viz)\n",
      "viz_op= opg.op.render(viz)\n",
      "cv2.imshow(\"viz\",viz_op)\n",
      "cv2.waitKey(0)\n",
      "cv2.destroyWindow(\"viz\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}