{
 "metadata": {
  "name": "",
  "signature": "sha256:3fb5c723a18dc43c97b3a5f6e5cb6bc7c28381f7170343d967516835a85a53fc"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cv2\n",
      "import numpy as np\n",
      "\n",
      "import PythonModel3dTracker.PyMBVAll as mbv\n",
      "import PythonModel3dTracker.Paths as Paths\n",
      "import PythonModel3dTracker.PythonModelTracker.DatasetInfo as dsi\n",
      "import PythonModel3dTracker.PythonModelTracker.OpenPoseGrabber as OPG\n",
      "import PythonModel3dTracker.PythonModelTracker.AutoGrabber as AutoGrabber\n",
      "import PythonModel3dTracker.Paths as Paths\n",
      "import BlenderMBV.BlenderMBVLib.RenderingUtils as ru\n",
      "import PythonModel3dTracker.PythonModelTracker.Model3dUtils as m3dutils\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/mad/Development/catkin_ws/src/ms1_perception/src/PythonModel3dTracker/PyMBVAll.py:1: RuntimeWarning: to-Python converter for std::vector<float, std::allocator<float> > already registered; second conversion method ignored.\n",
        "  import PyMBVCore as Core\n",
        "/home/mad/Development/catkin_ws/src/ms1_perception/src/PythonModel3dTracker/PyMBVAll.py:6: RuntimeWarning: to-Python converter for boost::function<void (cv::Mat_<double>&)> already registered; second conversion method ignored.\n",
        "  import PyMBVParticleFilter as PF\n",
        "/home/mad/Development/catkin_ws/src/ms1_perception/src/PythonModel3dTracker/PythonModelTracker/OpenPoseGrabber.py:2: RuntimeWarning: to-Python converter for cv::Mat already registered; second conversion method ignored.\n",
        "  import PyOpenPose as OP\n",
        "/home/mad/Development/catkin_ws/src/ms1_perception/src/PythonModel3dTracker/PythonModelTracker/OpenPoseGrabber.py:2: RuntimeWarning: to-Python converter for cv::Size_<int> already registered; second conversion method ignored.\n",
        "  import PyOpenPose as OP\n",
        "/home/mad/Development/catkin_ws/src/ms1_perception/src/PythonModel3dTracker/PythonModelTracker/OpenPoseGrabber.py:2: RuntimeWarning: to-Python converter for std::vector<cv::Mat, std::allocator<cv::Mat> > already registered; second conversion method ignored.\n",
        "  import PyOpenPose as OP\n",
        "/home/mad/Development/catkin_ws/src/ms1_perception/src/PythonModel3dTracker/PythonModelTracker/LandmarksGrabber.py:5: RuntimeWarning: to-Python converter for boost::shared_ptr<MBV::HandTracking::ObjectiveResultsCombination> already registered; second conversion method ignored.\n",
        "  import PyModel3dTracker as mt\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/mad/Development/catkin_ws/src/ms1_perception/src/PythonModel3dTracker/PythonModelTracker/LandmarksGrabber.py:5: RuntimeWarning: to-Python converter for std::__cxx11::list<unsigned long, std::allocator<unsigned long> > already registered; second conversion method ignored.\n",
        "  import PyModel3dTracker as mt\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dataset = 'mhad_s01_a04'\n",
      "params_ds = dsi.DatasetInfo()\n",
      "params_ds.generate(dataset)\n",
      "grabber = AutoGrabber.create_di(params_ds)\n",
      "opg = OPG.OpenPoseGrabber(model_op_path=Paths.models_openpose)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "images, calibs = grabber.grab()\n",
      "point_names, keypoints3d, keypoints2d, clb = opg.acquire(images, calibs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "person 0 Nose [ 211.9203949   122.07077026    0.85284293]\n",
        "person 0 neck [ 229.94139099  171.96713257    0.90738583]\n",
        "person 0 R.UArm [ 202.04627991  170.08081055    0.87641191]\n",
        "person 0 R.LArm [ 197.9125061   218.02832031    0.86750406]\n",
        "person 0 R.Wrist [ 185.99832153  261.90991211    0.85892105]\n",
        "person 0 L.UArm [ 250.01768494  172.02742004    0.84517473]\n",
        "person 0 L.LArm [ 262.00033569  228.01994324    0.87854463]\n",
        "person 0 L.Wrist [ 258.03451538  268.04766846    0.82357317]\n",
        "person 0 R.ULeg [ 208.01152039  265.99334717    0.78092176]\n",
        "person 0 R.LLeg [ 213.90013123  331.97756958    0.8679629 ]\n",
        "person 0 R.Foot [ 211.993927    385.95462036    0.86154634]\n",
        "person 0 L.ULeg [ 242.00204468  265.99411011    0.78002167]\n",
        "person 0 L.LLeg [ 250.0602417   337.97387695    0.81015623]\n",
        "person 0 L.Foot [ 261.9861145   396.03390503    0.86260402]\n",
        "person 0 R.eye [ 204.03909302  119.92331696    0.81368858]\n",
        "person 0 L.eye [ 216.02323914  118.08976746    0.95728999]\n",
        "person 0 R.ear [ 0.  0.  0.]\n",
        "person 0 L.ear [ 234.04742432  125.99485779    0.87714827]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/mad/Development/catkin_ws/src/ms1_perception/src/PythonModel3dTracker/PythonModelTracker/OpenPoseGrabber.py:154: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
        "  max(x-w, 0):min(x+w, width-1)])\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_name = \"mh_body_male_custom\"\n",
      "model3d = mbv.PF.Model3dMeta.create(str(Paths.model3d_dict[model_name][\"path\"]))\n",
      "model3d.parts.genBonesMap()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    \n",
      "def p2d_interp(p0, p1, n):\n",
      "    X = np.linspace(p0.x, p1.x, n, endpoint=False)\n",
      "    Y = np.linspace(p0.y, p1.y, n, endpoint=False)\n",
      "    points = mbv.Core.Vector2fStorage()\n",
      "    for x,y in zip(X,Y): points.append(mbv.Core.Vector2(x,y))\n",
      "    return points\n",
      "\n",
      "def p3d_interp(p0, p1, n):\n",
      "    X = np.linspace(p0.x, p1.x, n, endpoint=False)\n",
      "    Y = np.linspace(p0.y, p1.y, n, endpoint=False)\n",
      "    Z = np.linspace(p0.z, p1.z, n, endpoint=False)\n",
      "    points = mbv.Core.Vector3fStorage()\n",
      "    for x,y,z in zip(X,Y,Z): points.append(mbv.Core.Vector3(x,y,z))\n",
      "    return points\n",
      "\n",
      "def GetInterpKeypoints(point_names, keypoints3d, keypoints2d, interpolate_set=[], n_interp=5):\n",
      "    children = m3dutils.GetNodeChildren(model3d)\n",
      "    kp2d_dict = {}\n",
      "    for n,p2d in zip(point_names, keypoints2d[0]): kp2d_dict[n] = p2d\n",
      "    kp3d_dict = {}\n",
      "    for n,p3d in zip(point_names, keypoints3d[0]): kp3d_dict[n] = p3d\n",
      "        \n",
      "    default_set = [n for n in point_names if n not in interpolate_set]\n",
      "    \n",
      "    point_names_ = []\n",
      "    keypoints2d_ = mbv.Core.Vector2fStorage()\n",
      "    keypoints3d_ = mbv.Core.Vector3fStorage()\n",
      "    \n",
      "    for n in normal_set:\n",
      "        point_names_.append(n)\n",
      "        keypoints2d_.append(kp2d_dict[n])\n",
      "        keypoints3d_.append(kp3d_dict[n])\n",
      "    \n",
      "    \n",
      "    for n in interpolate_set:\n",
      "        p0 = kp2d_dict[n]\n",
      "        p1 = kp2d_dict[children[n][0]]\n",
      "        cur_p2d = p2d_interp(p0,p1,m)\n",
      "        for i,p in enumerate(cur_p2d): \n",
      "            lname = \"{0}_{1:02d}\".format(n, i)\n",
      "            point_names_.append(lname)\n",
      "            keypoints2d_.append(p)\n",
      "        \n",
      "        p0 = kp3d_dict[n]\n",
      "        p1 = kp3d_dict[children[n][0]]\n",
      "        cur_p3d = p3d_interp(p0,p1,m)\n",
      "        for p in cur_p3d: keypoints3d_.append(p)\n",
      "            \n",
      "        \n",
      "interpolate_set = [\"R.UArm\", \"R.LArm\",\"R.ULeg\", \"R.LLeg\",\"L.UArm\", \"L.LArm\",\"L.ULeg\", \"L.LLeg\"]\n",
      "point_names_, keypoints3d_, keypoints2d_ = \\\n",
      "    GetInterpKeypoints(point_names, keypoints3d, keypoints2d, interpolate_set=interpolate_set, n_interp=5)\n",
      "\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "global name 'normal_set' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-19-562f5726218e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0minterpolate_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"R.UArm\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"R.LArm\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"R.ULeg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"R.LLeg\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"L.UArm\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"L.LArm\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"L.ULeg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"L.LLeg\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0mpoint_names_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeypoints3d_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeypoints2d_\u001b[0m \u001b[0;34m=\u001b[0m     \u001b[0mGetInterpKeypoints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoint_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeypoints3d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeypoints2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolate_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolate_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_interp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-19-562f5726218e>\u001b[0m in \u001b[0;36mGetInterpKeypoints\u001b[0;34m(point_names, keypoints3d, keypoints2d, interpolate_set, n_interp)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mkeypoints3d_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmbv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVector3fStorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnormal_set\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mpoint_names_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mkeypoints2d_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkp2d_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: global name 'normal_set' is not defined"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "viz = images[1]\n",
      "viz = ru.disp_points(points, viz)\n",
      "viz_op= opg.op.render(viz)\n",
      "cv2.imshow(\"viz\",viz_op)\n",
      "cv2.waitKey(0)\n",
      "cv2.destroyWindow(\"viz\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}